{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bills.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06ZuEVn-Q-LE"
      },
      "source": [
        "Import some data from govtrack.us.\n",
        "\n",
        "We will create a file on Colab's hard drive. There are more places to load data from: https://neptune.ai/blog/google-colab-dealing-with-files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al_0dkeROXJ2"
      },
      "source": [
        "import csv\n",
        "import os\n",
        "from typing import Tuple\n",
        "\n",
        "import bs4\n",
        "import requests\n",
        "# \"https://www.govtrack.us/congress/bills/116/hr221/summary\"\n",
        "# \"https://www.govtrack.us/congress/bills/116/hr221\"\n",
        "\n",
        "NO_SUCH_BILL = \"NO SUCH BILL\"\n",
        "\n",
        "\n",
        "def get_summary(bill_id: int) -> str:\n",
        "    summary_url = f\"https://www.govtrack.us/congress/bills/116/hr{bill_id}/summary\"\n",
        "    summary_html = requests.get(summary_url)\n",
        "    if summary_html.status_code == 404:\n",
        "        return NO_SUCH_BILL\n",
        "\n",
        "    soup = bs4.BeautifulSoup(summary_html.text, 'html.parser')\n",
        "    summary = soup.find(\"div\", {\"id\": \"libraryofcongress\"})\n",
        "    summary_parts = []\n",
        "    if not hasattr(summary, \"contents\"):\n",
        "        print()\n",
        "    if len(summary.contents) < 4:\n",
        "        if \"No summary available.\" in summary.text:\n",
        "            return \"No summary available.\"\n",
        "        print(summary.text)\n",
        "        raise TypeError('uh oh')\n",
        "\n",
        "    for element in summary.contents[3]:\n",
        "        if \"<script>\" in str(element):\n",
        "            continue\n",
        "        if not hasattr(element, \"text\"):\n",
        "            continue\n",
        "        text = element.text\n",
        "        if text.strip():\n",
        "            summary_parts.append(text)\n",
        "    return \"\\n\".join(summary_parts)\n",
        "\n",
        "\n",
        "def get_status(bill_id: int) -> str:\n",
        "    status_url = f\"https://www.govtrack.us/congress/bills/116/hr{bill_id}\"\n",
        "    status_html = requests.get(status_url)\n",
        "    if status_html.status_code == 404:\n",
        "        return NO_SUCH_BILL\n",
        "\n",
        "    soup = bs4.BeautifulSoup(status_html.text, 'html.parser')\n",
        "    # oh this is so fragile\n",
        "    rows = soup.findAll(\"div\", {\"class\": [\"row\"]})\n",
        "    status = None\n",
        "    for row in rows:\n",
        "        status = row.findAll(\"div\", {\"class\": [\"col-sm-9\", \"col-md-10\"]})\n",
        "        if status:\n",
        "            break\n",
        "    if not status:\n",
        "        raise TypeError(\"Can't find it\")\n",
        "    summary_parts = []\n",
        "    if \"Died in a previous Congress\" in str(status[1].contents):\n",
        "        return \"Died in a previous Congress\"\n",
        "    if \"incorporated\" in str(status[1].contents):\n",
        "        return \"Incorporated into another bill\"\n",
        "    for element in status[1].contents:\n",
        "        if \"<script>\" in str(element):\n",
        "            continue\n",
        "        if not hasattr(element, \"text\"):\n",
        "            continue\n",
        "        text = element.text\n",
        "        if text.strip() and \"—\" in text:\n",
        "            summary_parts.append(text.split(\"—\")[0].strip())\n",
        "    if not summary_parts:\n",
        "        print(\"Uh oh\")\n",
        "        print(status[1].contents)\n",
        "    return \"\\n\".join(summary_parts)\n",
        "\n",
        "\n",
        "def locate_file(file_name: str, executing_file: str) -> str:\n",
        "    \"\"\"\n",
        "    Find file relative to a source file, e.g.\n",
        "    locate(\"foo/bar.txt\", __file__)\n",
        "\n",
        "    Succeeds regardless to context of execution\n",
        "    \"\"\"\n",
        "    file_path = os.path.join(\n",
        "        os.path.dirname(os.path.abspath(executing_file)), file_name\n",
        "    )\n",
        "    return file_path\n",
        "\n",
        "\n",
        "def load_all(start: int, end: int) -> Tuple[int, int]:\n",
        "    # file_name = locate_file(\"data2.csv\", __file__)\n",
        "    file_name = \"data.csv\"\n",
        "    try:\n",
        "      os.remove(file_name)\n",
        "    except FileNotFoundError:\n",
        "      pass\n",
        "    success = 0\n",
        "    errors = 0\n",
        "    with open(file_name, 'a', newline='') as csvfile:\n",
        "        for bill_id in range(start, end):\n",
        "            try:\n",
        "                summary = get_summary(bill_id=bill_id)\n",
        "                if summary == NO_SUCH_BILL:\n",
        "                    continue\n",
        "                status = get_status(bill_id=bill_id)\n",
        "                writer = csv.writer(csvfile)\n",
        "                writer.writerow([bill_id, status, summary])\n",
        "                print(bill_id, \"status\", status, \"summary\",\n",
        "                      summary.split(\"\\n\")[0][0:80] + \"...\")\n",
        "                success += 1\n",
        "            except Exception as ex:\n",
        "                errors += 1\n",
        "                print(ex)\n",
        "    return success, errors\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCReQOc5mpuv"
      },
      "source": [
        "Load data from original source. This is slow, consider using the prebuilt dataset in next step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igA7Z1mGOynm",
        "outputId": "7d6d37c8-98cf-4cbb-edd5-374548e2955d"
      },
      "source": [
        "load_all(1, 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 status Died in a previous Congress summary For the People Act of 2019...\n",
            "2 status Died in a previous Congress summary Investing in a New Vision for the Environment and Surface Transportation in Amer...\n",
            "3 status Died in a previous Congress summary Elijah E. Cummings Lower Drug Costs Now Act...\n",
            "4 status Died in a previous Congress summary Voting Rights Advancement Act of 2019...\n",
            "5 status Died in a previous Congress summary Equality Act...\n",
            "6 status Died in a previous Congress summary American Dream and Promise Act of 2019...\n",
            "7 status Died in a previous Congress summary Paycheck Fairness Act...\n",
            "8 status Died in a previous Congress summary Bipartisan Background Checks Act of 2019...\n",
            "9 status Died in a previous Congress summary Climate Action Now Act...\n",
            "11 status Died in a previous Congress summary No summary available....\n",
            "12 status Died in a previous Congress summary China Task Force Act or the CTF Act...\n",
            "13 status Died in a previous Congress summary No summary available....\n",
            "14 status Died in a previous Congress summary No summary available....\n",
            "19 status Died in a previous Congress summary No summary available....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqNOmmakm1JY"
      },
      "source": [
        "Here we load the data from Github. 1000 rows of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6rAmvOFVRUs9",
        "outputId": "e45eb5cd-1325-4949-c21f-c61a2675907c"
      },
      "source": [
        "import itertools\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "\n",
        "# Use a file that you download\n",
        "# input_file = \"data.csv\"\n",
        "# comma delimited is the default\n",
        "# df = pd.read_csv(input_file,\n",
        "#                  names=[\"bill_id\", \"status\", \"summary\"],\n",
        "#                  encoding='cp1252')\n",
        "\n",
        "# use a premade file\n",
        "url=\"https://raw.githubusercontent.com/matthewdeanmartin/bills_with_nlp/main/data.csv\"\n",
        "s=requests.get(url).content\n",
        "df=pd.read_csv(io.StringIO(s.decode('cp1252')),\n",
        "              names=[\"bill_id\", \"status\", \"summary\"])\n",
        "\n",
        "df.head()\n",
        "\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bill_id</th>\n",
              "      <th>status</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Died in a previous Congress</td>\n",
              "      <td>For the People Act of 2019\\nThis bill addresse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Died in a previous Congress</td>\n",
              "      <td>Investing in a New Vision for the Environment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Died in a previous Congress</td>\n",
              "      <td>Elijah E. Cummings Lower Drug Costs Now Act\\nT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Died in a previous Congress</td>\n",
              "      <td>Voting Rights Advancement Act of 2019\\nThis bi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Died in a previous Congress</td>\n",
              "      <td>Equality Act\\nThis bill prohibits discriminati...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bill_id  ...                                            summary\n",
              "0        1  ...  For the People Act of 2019\\nThis bill addresse...\n",
              "1        2  ...  Investing in a New Vision for the Environment ...\n",
              "2        3  ...  Elijah E. Cummings Lower Drug Costs Now Act\\nT...\n",
              "3        4  ...  Voting Rights Advancement Act of 2019\\nThis bi...\n",
              "4        5  ...  Equality Act\\nThis bill prohibits discriminati...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4XfPRiOnKg_"
      },
      "source": [
        "Stemming removes some noise from the data, in particular, we don't want to be so strict about what words are the same. \"Apple\", \"Apples\" should be treated as the same work. Also remove noise like numbers and things that are numberlike."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0eWM14YGdFM1",
        "outputId": "f141cedf-63a7-4caf-f6a3-56e2973e2fcd"
      },
      "source": [
        "# show stemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "ps = PorterStemmer()\n",
        " \n",
        "# choose some words to be stemmed\n",
        "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\"]\n",
        "def stem(text):\n",
        "  stems = (ps.stem(w.translate(str.maketrans('', '', string.punctuation))) for w in text.split())\n",
        "  word_stems = filter(lambda x: x.isalpha(), stems)\n",
        "  return \" \".join(word_stems)\n",
        "\n",
        "df[\"summary\"] = df[\"summary\"].apply(stem)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bill_id</th>\n",
              "      <th>status</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Died in a previous Congress</td>\n",
              "      <td>for the peopl act of thi bill address voter ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Died in a previous Congress</td>\n",
              "      <td>invest in a new vision for the environ and sur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Died in a previous Congress</td>\n",
              "      <td>elijah E cum lower drug cost now act thi bill ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Died in a previous Congress</td>\n",
              "      <td>vote right advanc act of thi bill establish ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Died in a previous Congress</td>\n",
              "      <td>equal act thi bill prohibit discrimin base on ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bill_id  ...                                            summary\n",
              "0        1  ...  for the peopl act of thi bill address voter ac...\n",
              "1        2  ...  invest in a new vision for the environ and sur...\n",
              "2        3  ...  elijah E cum lower drug cost now act thi bill ...\n",
              "3        4  ...  vote right advanc act of thi bill establish ne...\n",
              "4        5  ...  equal act thi bill prohibit discrimin base on ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3kg-z_44Gps"
      },
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "try:\n",
        "  sia = SentimentIntensityAnalyzer()\n",
        "except LookupError:\n",
        "  nltk.download('vader_lexicon')\n",
        "  sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "sia.polarity_scores(\"Wow, NLTK is really powerful!\")\n",
        "\n",
        "# {'compound': 0.8012, 'neg': 0.0, 'neu': 0.295, 'pos': 0.705}\n",
        "def sentiment(text, kind):\n",
        "  scores = sia.polarity_scores(text)\n",
        "  return scores[kind]\n",
        "\n",
        "df[\"summary_compound\"] = df[\"summary\"].apply(lambda x: sentiment(x, \"compound\"))\n",
        "df[\"summary_negative\"] = df[\"summary\"].apply(lambda x: sentiment(x, \"neg\"))\n",
        "df[\"summary_neu\"] = df[\"summary\"].apply(lambda x: sentiment(x, \"neu\"))\n",
        "df[\"summary_pos\"] = df[\"summary\"].apply(lambda x: sentiment(x, \"pos\"))\n",
        "\n"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNsHxaY1ndfe"
      },
      "source": [
        "Now we get the data into a format that sklearn can use-- we spit columns into X's (predictors) and Y's (things to be predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwH8ZWJzchn8",
        "outputId": "acde80f5-7d98-4841-c576-89782c1596fa"
      },
      "source": [
        "# Getting features of dataframe\n",
        "# Same as SELECT feature1, feature2, feature3 FROM data\n",
        "# X = data[[\"feature1\", \"feature2\", \"feature3\"]]\n",
        "USE_VECTORIZOR = True\n",
        "if USE_VECTORIZOR:\n",
        "  vectorizer = CountVectorizer(\n",
        "      # remove a, an, the, etc.\n",
        "      stop_words='english',\n",
        "      # common words only\n",
        "      min_df=15\n",
        "  )\n",
        "  X = vectorizer.fit_transform(df[\"summary\"])\n",
        "  print(f\"Feature count : {len(vectorizer.get_feature_names())}\")\n",
        "  print(vectorizer.get_feature_names())\n",
        "\n",
        "  # This is a big sparse grid of mostly 0s\n",
        "  print(X.toarray())\n",
        "\n",
        "  print(pd.DataFrame(X.toarray()).info())\n",
        "else:\n",
        "  X = df[[\"summary_compound\", \"summary_negative\", \"summary_neu\", \"summary_pos\"]]\n",
        "  print(X.info())\n",
        "\n",
        "# Check for unbalanced groups. If we had 2 were enacted and 998 died, then\n",
        "# our model doesn't have enough information to say anything about enacted bills\n",
        "print(\"Bill status\")\n",
        "y = df['status']  # Labels\n",
        "print(y.value_counts())\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "# Set random state to make runs repeatable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=42)\n"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature count : 594\n",
            "['abort', 'accept', 'access', 'accord', 'account', 'acquir', 'acr', 'act', 'action', 'activ', 'addit', 'address', 'adjust', 'administ', 'administr', 'advanc', 'advers', 'affair', 'affect', 'afford', 'age', 'agenc', 'agent', 'agreement', 'agricultur', 'aid', 'alien', 'alloc', 'allow', 'altern', 'amend', 'america', 'american', 'ani', 'annual', 'anoth', 'appli', 'applic', 'appoint', 'appropri', 'approv', 'approxim', 'area', 'arm', 'assess', 'assist', 'associ', 'author', 'avail', 'award', 'bank', 'barrier', 'base', 'basi', 'becaus', 'becom', 'befor', 'begin', 'benefit', 'block', 'board', 'border', 'boundari', 'branch', 'budget', 'build', 'bureau', 'busi', 'california', 'capac', 'capit', 'care', 'carri', 'case', 'categori', 'caus', 'center', 'certain', 'certif', 'certifi', 'chang', 'child', 'children', 'circumst', 'citi', 'citizen', 'civil', 'claim', 'clean', 'coast', 'code', 'collect', 'columbia', 'combat', 'commerc', 'commiss', 'commit', 'committe', 'commun', 'compani', 'compens', 'competit', 'complet', 'compli', 'complianc', 'compon', 'concern', 'condit', 'conduct', 'congress', 'congression', 'connect', 'conserv', 'consid', 'consider', 'consist', 'construct', 'consum', 'contain', 'continu', 'contract', 'contractor', 'contribut', 'control', 'convey', 'convict', 'cooper', 'coordin', 'corpor', 'cost', 'counsel', 'counti', 'countri', 'court', 'cover', 'coverag', 'creat', 'credit', 'crime', 'crimin', 'criteria', 'current', 'data', 'date', 'day', 'death', 'decemb', 'declar', 'deduct', 'deem', 'defens', 'defin', 'definit', 'degre', 'depart', 'depend', 'design', 'determin', 'develop', 'dh', 'direct', 'disabl', 'discharg', 'disclos', 'disclosur', 'discrimin', 'diseas', 'dispos', 'distribut', 'district', 'document', 'doe', 'doj', 'drug', 'dure', 'duti', 'econom', 'educ', 'effect', 'effici', 'effort', 'elect', 'elig', 'elimin', 'emerg', 'employ', 'employe', 'enact', 'encourag', 'end', 'energi', 'enforc', 'engag', 'engin', 'enhanc', 'enrol', 'ensur', 'enter', 'entiti', 'entitl', 'entri', 'environment', 'equal', 'equip', 'establish', 'estim', 'evalu', 'examin', 'exceed', 'exchang', 'exclud', 'execut', 'exempt', 'exist', 'expand', 'expenditur', 'expens', 'expir', 'extend', 'facil', 'fail', 'fair', 'famili', 'feder', 'fee', 'file', 'final', 'financ', 'financi', 'fine', 'firearm', 'fiscal', 'follow', 'food', 'forc', 'foreign', 'forest', 'form', 'forth', 'fund', 'furnish', 'ga', 'gener', 'good', 'govern', 'grant', 'gross', 'group', 'guarante', 'guard', 'guidanc', 'gun', 'ha', 'hazard', 'health', 'held', 'help', 'hh', 'higher', 'hire', 'histor', 'hold', 'home', 'homeland', 'hospit', 'hour', 'hous', 'human', 'identif', 'identifi', 'immedi', 'immigr', 'impact', 'implement', 'import', 'impos', 'improv', 'includ', 'incom', 'increas', 'incur', 'independ', 'indian', 'individu', 'inform', 'infrastructur', 'initi', 'innov', 'institut', 'insur', 'integr', 'intellig', 'intend', 'interior', 'intern', 'invest', 'investig', 'involv', 'island', 'issu', 'item', 'job', 'joint', 'judici', 'jurisdict', 'justic', 'known', 'labor', 'land', 'laps', 'law', 'leas', 'legal', 'legisl', 'level', 'licens', 'life', 'limit', 'list', 'loan', 'local', 'locat', 'maintain', 'mainten', 'major', 'make', 'manag', 'manufactur', 'market', 'materi', 'matter', 'maximum', 'mean', 'measur', 'medic', 'medicaid', 'medicar', 'meet', 'member', 'method', 'mexico', 'militari', 'miner', 'minimum', 'modifi', 'monitor', 'month', 'nation', 'natur', 'necessari', 'need', 'network', 'new', 'nonprofit', 'notic', 'notif', 'notifi', 'number', 'oblig', 'obtain', 'occur', 'offens', 'offer', 'offic', 'offici', 'oil', 'onli', 'oper', 'opportun', 'order', 'organ', 'origin', 'otherwis', 'outsid', 'owner', 'paid', 'parent', 'park', 'parti', 'particip', 'patient', 'pay', 'payment', 'penalti', 'percentag', 'perform', 'period', 'perman', 'permit', 'person', 'personnel', 'physic', 'physician', 'pilot', 'place', 'plan', 'polici', 'polit', 'portion', 'posit', 'possess', 'post', 'postal', 'potenti', 'practic', 'premium', 'prepar', 'present', 'preserv', 'presid', 'presidenti', 'prevent', 'price', 'primari', 'prior', 'prison', 'privat', 'procedur', 'proceed', 'process', 'product', 'profession', 'program', 'prohibit', 'project', 'promot', 'properti', 'propos', 'prosecut', 'protect', 'provid', 'provis', 'public', 'publish', 'purchas', 'purpos', 'qualifi', 'qualiti', 'rate', 'reason', 'reauthor', 'receipt', 'receiv', 'recipi', 'recogn', 'recommend', 'record', 'recreat', 'reduc', 'reduct', 'refer', 'reform', 'regard', 'region', 'regist', 'registr', 'regul', 'regular', 'regulatori', 'relat', 'releas', 'relief', 'remain', 'remov', 'renew', 'repeal', 'replac', 'report', 'repres', 'request', 'requir', 'research', 'reserv', 'resid', 'resolut', 'resourc', 'respect', 'respond', 'respons', 'restor', 'restrict', 'result', 'retir', 'return', 'revenu', 'review', 'revis', 'right', 'risk', 'river', 'rule', 'rural', 'safeti', 'salari', 'sale', 'save', 'schedul', 'school', 'scienc', 'sec', 'secondari', 'secur', 'seek', 'separ', 'serv', 'servic', 'set', 'sever', 'shall', 'share', 'shutdown', 'signific', 'small', 'social', 'sole', 'sourc', 'special', 'specif', 'specifi', 'spend', 'spous', 'standard', 'state', 'statu', 'statutori', 'strategi', 'student', 'studi', 'subject', 'submit', 'subsequ', 'substanti', 'summari', 'suppli', 'support', 'survivor', 'taken', 'task', 'tax', 'taxpay', 'technic', 'technolog', 'temporari', 'term', 'termin', 'territori', 'terrorist', 'test', 'thi', 'thing', 'threat', 'time', 'titl', 'total', 'trade', 'traffick', 'train', 'transfer', 'transpar', 'transport', 'travel', 'treasuri', 'treat', 'treatment', 'tribal', 'tribe', 'trust', 'type', 'unit', 'unlaw', 'unless', 'urban', 'use', 'va', 'valu', 'variou', 'vehicl', 'veteran', 'victim', 'violat', 'violenc', 'visa', 'vote', 'wa', 'waiv', 'wast', 'water', 'websit', 'women', 'work', 'worker', 'written', 'year', 'zone']\n",
            "[[0 0 2 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 994 entries, 0 to 993\n",
            "Columns: 594 entries, 0 to 593\n",
            "dtypes: int64(594)\n",
            "memory usage: 4.5 MB\n",
            "None\n",
            "Bill status\n",
            "Died in a previous Congress       872\n",
            "Incorporated into another bill     90\n",
            "Enacted                            32\n",
            "Name: status, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtfCDwYm7bcb"
      },
      "source": [
        "Now we check if our model works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzWNYE-kmnEo",
        "outputId": "aca350d8-81c2-4b59-c825-3e9bfc0befd9"
      },
      "source": [
        "\n",
        "# Random forests are a good model for when you have many features and relatively\n",
        "# few data points (e.g. 10,000s of predictive words, yet only 100s of bills)\n",
        "# Set random state to make runs repeatable\n",
        "USE_RANDOM_FOREST = True\n",
        "if USE_RANDOM_FOREST:\n",
        "  clf = RandomForestClassifier(n_estimators=250, random_state=42)\n",
        "else:\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  clf = LogisticRegression(\n",
        "      solver='newton-cg'\n",
        "  )\n",
        "# Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "pd.DataFrame(y_pred).head()\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "# print(clf.feature_importances_)\n",
        "i = 0\n",
        "\n",
        "if not USE_RANDOM_FOREST:\n",
        "  coefs = clf.coef_.tolist()  \n",
        "  for coef_for_category in coefs:  \n",
        "    pairs = list(zip(vectorizer.get_feature_names(), coef_for_category))\n",
        "    print(clf.classes_[i])\n",
        "    for key, value in pairs:\n",
        "      if abs(value)>.50:\n",
        "        print(f\"{key}: {value}, \", end=\"\")\n",
        "    i += 1\n",
        "    print()\n"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9036144578313253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vceh9Ert7ICB"
      },
      "source": [
        "Importances is an attempt to list which predictors matter and which don't matter at all. The feature might increase or decrease the odds of a given classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gkzn_p67Goa",
        "outputId": "cc15ef62-eb8a-4b3f-9504-9fc7938fec28"
      },
      "source": [
        "if USE_VECTORIZOR:\n",
        "  # should use pandas way...\n",
        "  importances = list(zip(vectorizer.get_feature_names(), clf.feature_importances_))\n",
        "  importances.sort(key=lambda x:x[1])\n",
        "  importances = filter(lambda score: score[1] > 0, importances)\n",
        "\n",
        "  i = 0\n",
        "  for feat, importance in itertools.islice(importances, 20):\n",
        "      if importance == 0:\n",
        "          continue\n",
        "      print('feature: {f}, importance: {i}'.format(f=feat, i=importance))\n",
        "      i +=1 \n",
        "\n",
        "  print(f\"Features scored: {i}\")\n",
        "else:\n",
        "  #  0   summary_compound  994 non-null    float64\n",
        "  #  1   summary_negative  994 non-null    float64\n",
        "  #  2   summary_neu       994 non-null    float64\n",
        "  #  3   summary_pos       994 non-null    float64\n",
        "  print(clf.feature_importances_)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3471939  0.12831351 0.27157527 0.25291732]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}